# IndiGo RAG Bot (VS Code Ready)

Run your multiâ€‘PDF â†’ Chroma â†’ Groq Q&A/Chat/Summary/Quiz app **locally** in VS Code.

## Quick Start


---

````markdown
# âœˆï¸ IndiGo RAG Chatbot â€“ Document Q&A

A **Retrieval-Augmented Generation (RAG)** based chatbot designed for querying PDF documents with precision.  
Powered by **Groq LLaMA-3**, **LangChain**, **ChromaDB**, and **Streamlit** â€” built for fast, contextual responses.

---

## ğŸ“½ Demo Video  
**[â–¶ Watch the Video](https://drive.google.com/file/d/1prWTHqUt76tMGLHutOZElbROh1Peq2nI/view?usp=sharing)**  

---

## ğŸš€ Features
- ğŸ“„ Upload multiple PDF documents
- ğŸ” Query using natural language
- ğŸ§  Uses **Groq LLaMA-3** for lightning-fast responses
- ğŸ—„ Document embeddings stored in **ChromaDB**
- ğŸ“Š Summarization & MCQ quiz generation
- ğŸ¨ Modern **Streamlit** UI

---

## âš¡ Run the Chatbot

You can run this project in **two ways**:

---

### **Option 1 â€“ Run in Google Colab (Cloud)**
No installation required! Run directly in the browser.

1. Open the Colab Notebook:  
   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](YOUR_COLAB_NOTEBOOK_LINK_HERE)
   
2. Upload your PDF files inside the notebook.

3. Enter your **GROQ_API_KEY** when prompted.

4. Click **Run All** â€” the Streamlit app will launch in Colab.

---

### **Option 2 â€“ Run Locally in VS Code**
Run directly on your system for full control.

#### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/PriyanshuInterGlobe18/Indigo-Chatbot-Assignment-1.git
cd Indigo-Chatbot-Assignment-1
````

#### 2ï¸âƒ£ Create & Activate Virtual Environment (Optional but Recommended)

```bash
python -m venv .venv
```

**For Windows:**

```bash
.venv\Scripts\activate
```

**For macOS/Linux:**

```bash
source .venv/bin/activate
```

#### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

#### 4ï¸âƒ£ Add Your API Key

```bash
cp .env.example .env
```

Edit `.env` and add:

```
GROQ_API_KEY=your_api_key_here
```

#### 5ï¸âƒ£ Run the App

```bash
streamlit run app.py
```

---

## ğŸ“‚ Project Structure

```
Indigo-Chatbot-Assignment-1/
â”‚â”€â”€ vscode/               # VS Code project files
â”‚â”€â”€ images/               # Screenshots for README
â”‚â”€â”€ app.py                 # Streamlit app
â”‚â”€â”€ rag_core.py            # RAG logic
â”‚â”€â”€ requirements.txt       # Python dependencies
â”‚â”€â”€ README.md              # Project documentation
â”‚â”€â”€ .env.example           # Example environment variables
```

---

---


```


# âœˆï¸ IndiGo RAG Chatbot â€“ AI-Powered Procurement Assistant

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Streamlit](https://img.shields.io/badge/Framework-Streamlit-ff4b4b)
![LangChain](https://img.shields.io/badge/AI-LangChain-00b3b3)
![ChromaDB](https://img.shields.io/badge/VectorDB-ChromaDB-green)
![License](https://img.shields.io/badge/License-MIT-yellow)

> An AI-powered chatbot designed for **IndiGo Airlinesâ€™ procurement process**, capable of answering document-based queries, summarizing sourcing manuals, and generating quiz questions.  
> Built with **LangChain**, **RAG (Retrieval-Augmented Generation)**, **ChromaDB**, and **Streamlit** â€” integrated with **Groqâ€™s LLaMA3** for lightning-fast inference.

---

## ğŸ¥ Live Demo

| Feature                | Preview |
|------------------------|---------|
| **PDF Upload & Query** | ![Upload & Ask](docs/gifs/upload_and_ask.gif) |
| **Summarization**      | ![Summarization](docs/gifs/summarization.gif) |
| **Quiz Generation**    | ![Quiz Generation](docs/gifs/quiz_generation.gif) |

*(GIFs recorded at 720p for clarity â€” place them in `docs/gifs/` in your repo)*

---

## ğŸš€ Features (Detailed)

### ğŸ“„ 1. Document Upload & Search  
Easily upload PDF documents (such as the *IndiGo Sourcing Training Manual*).  
The chatbot indexes the content using embeddings so you can **search instantly** for any keyword, phrase, or concept.

---

### ğŸ” 2. Retrieval-Augmented Generation (RAG)  
The chatbot uses **RAG** to pull relevant document sections before answering.  
This ensures that every answer is:
- Contextually accurate.
- Grounded in your documentâ€™s actual content.
- Transparent, with relevant references.

---

### ğŸ“ 3. Intelligent Summarization  
Upload a lengthy procurement guide and get:
- Bullet-point summaries for quick reading.
- Condensed key points without losing meaning.
Perfect for **briefing managers or training staff**.

---

### ğŸ¯ 4. Quiz Generation for Training  
Automatically generate quiz questions from uploaded documents.  
Ideal for:
- Staff onboarding.
- Compliance training.
- Refreshing team knowledge on procedures.

---

### âš¡ 5. Groq LLaMA3 Integration (Switchable Models)  
The chatbot uses **Groqâ€™s LLaMA3 models** by default, offering:
- Lightning-fast inference speeds.
- Low latency for a smoother UX.
You can **switch to other available Groq models** from the sidebar dropdown for testing or performance comparison.

---

### ğŸŒ 6. Public Sharing via Cloudflare Tunnel  
Easily run the app on **Google Colab** and share a **public link** with your team.  
The app even displays a **big, bold, clickable link** in Colab for instant access.

---

### ğŸ›¡ï¸ 7. Role-Based and Multi-Action UI  
The chatbot supports:
- **Query Mode** â€“ Ask document-based questions.
- **Summarize Mode** â€“ Condense lengthy docs.
- **Quiz Mode** â€“ Create training questions.

---

## ğŸ› ï¸ Tech Stack (Detailed)

- **Python 3.10+** â€“ Core programming language for the application.
- **[Streamlit](https://streamlit.io/)** â€“ Interactive frontend framework to build the chatbot UI quickly and with minimal code.
- **[LangChain](https://www.langchain.com/)** â€“ Orchestration layer for:
  - Chaining prompts.
  - Handling retrieval.
  - Managing summarization and quiz generation pipelines.
- **[ChromaDB](https://www.trychroma.com/)** â€“ Vector database for storing and retrieving document embeddings.
- **[Sentence-Transformers](https://www.sbert.net/)** â€“ Used for creating high-quality text embeddings.  
  *Embedder:* `"all-MiniLM-L6-v2"` (fast & lightweight, ~384-dim vector size).  
- **[Groq API](https://groq.com/)** â€“ Provides access to LLaMA3 models for ultra-low latency inference.  
  *Model Parameters:* temperature = `0.0` (factual responses), max_tokens = `1024` (long answers).
- **[pypdf](https://pypi.org/project/pypdf/)** â€“ Extracts text from uploaded PDFs.
- **Google Colab + Cloudflare Tunnel** â€“ Deployment for demos without local setup.
- **[LangSmith](https://smith.langchain.com/)** â€“ Optional integration for tracing, debugging, and tracking chatbot runs.

---

## ğŸ“‚ Project Structure

